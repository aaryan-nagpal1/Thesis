# Thesis
üìå Overview

This repository contains the complete implementation for my undergraduate thesis at the Human Factors & Applied Statistics Lab (HFAST), University of Toronto.
The project investigates whether driver drowsiness and degraded cognitive states can be detected reliably using multi-modal high-frequency driver monitoring data.

The goal is to design a fully reproducible driver state inference pipeline integrating:
	‚Ä¢	Multi-modal sensor streams (face, gaze, pose, driving dynamics, physiological signals)
	‚Ä¢	Sliding-window time-series feature extraction (30s overlap windows)
	‚Ä¢	Catch22 and statistical time-domain features
	‚Ä¢	Label harmonization and unified annotation structure
	‚Ä¢	Classical ML models for interpretable classification
	‚Ä¢	Full evaluation pipeline (accuracy, F1, confusion matrices, SHAP, ablations)

This system is designed to support real-time or near-real-time deployment in intelligent vehicles, with an emphasis on interpretability, robustness, and ease of integration into larger driver monitoring systems.


Drowsy driving is a major cause of vehicle accidents, yet existing in-vehicle monitoring solutions often rely on:
	‚Ä¢	Single-modal signals (eyelid closure only)
	‚Ä¢	Low-frequency features
	‚Ä¢	Poor generalization across drivers, lighting conditions, or environments

This thesis explores whether multi-modality + time-series features can significantly improve accuracy, stability, and early-warning detection.


üîß Feature Engineering

Sliding Windows

All signals are aggregated into 30-second sliding windows with configurable overlap.
Window features include:
	‚Ä¢	Means & standard deviations for 20 time-series channels
	‚Ä¢	Catch22 features for each variable (440 total features per window)
	‚Ä¢	Lane-based SD & steering reversal rate
	‚Ä¢	ECG-derived HRV metrics
	‚Ä¢	GSR peak features

Label Unification

Different experimental labels are collapsed into:
	‚Ä¢	Label_unify: human-readable state classes
	‚Ä¢	Label_num: integer-coded classes for modeling

  ü§ñ Models Implemented

The pipeline supports:
	‚Ä¢	Random Forest
	‚Ä¢	XGBoost
	‚Ä¢	Support Vector Machines
	‚Ä¢	Logistic Regression
	‚Ä¢	LightGBM (optional)
	‚Ä¢	Baseline majority classifier

All models include hyperparameter search via Optuna.

üîç Key Findings (Short Summary)
	‚Ä¢	Multi-modal fusion substantially outperforms single-modality baselines
	‚Ä¢	Catch22 features provide strong discriminative power for physiological signals
	‚Ä¢	Steering reversal rate + lane SD improve early detection
	‚Ä¢	Face-only models underperform in low-light or off-angle conditions
	‚Ä¢	Ablation studies show physiology + behavior fusion yields highest robustness
  
üß≠ Future Work
	‚Ä¢	Integrating deep learning models (TCN, Transformer-based temporal encoders)
	‚Ä¢	Real-time inference optimization
	‚Ä¢	On-device EdgeML deployment
	‚Ä¢	Cross-driver generalization using domain adaptation
	‚Ä¢	End-to-end multi-signal sensor fusion networks
