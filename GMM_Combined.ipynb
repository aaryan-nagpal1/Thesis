{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1f9af2",
   "metadata": {},
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7455cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     76\u001b[39m     gmm = GaussianMixture(\n\u001b[32m     77\u001b[39m         n_components=K,\n\u001b[32m     78\u001b[39m         covariance_type=cov_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m         random_state=RANDOM_STATE\n\u001b[32m     85\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[43mgmm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     bic = gmm.bic(X_train_s)\n\u001b[32m     89\u001b[39m     aic = gmm.aic(X_train_s)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_base.py:182\u001b[39m, in \u001b[36mBaseMixture.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[32m    157\u001b[39m \n\u001b[32m    158\u001b[39m \u001b[33;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    179\u001b[39m \u001b[33;03m    The fitted mixture.\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_base.py:250\u001b[39m, in \u001b[36mBaseMixture.fit_predict\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.max_iter + \u001b[32m1\u001b[39m):\n\u001b[32m    248\u001b[39m     prev_lower_bound = lower_bound\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     log_prob_norm, log_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28mself\u001b[39m._m_step(X, log_resp)\n\u001b[32m    252\u001b[39m     lower_bound = \u001b[38;5;28mself\u001b[39m._compute_lower_bound(log_resp, log_prob_norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_base.py:312\u001b[39m, in \u001b[36mBaseMixture._e_step\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    297\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"E step.\u001b[39;00m\n\u001b[32m    298\u001b[39m \n\u001b[32m    299\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m        the point of each sample in X.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     log_prob_norm, log_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(log_prob_norm), log_resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_base.py:532\u001b[39m, in \u001b[36mBaseMixture._estimate_log_prob_resp\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_log_prob_resp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    514\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[32m    515\u001b[39m \n\u001b[32m    516\u001b[39m \u001b[33;03m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    530\u001b[39m \u001b[33;03m        logarithm of the responsibilities\u001b[39;00m\n\u001b[32m    531\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     weighted_log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_weighted_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m     log_prob_norm = logsumexp(weighted_log_prob, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(under=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    535\u001b[39m         \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_base.py:485\u001b[39m, in \u001b[36mBaseMixture._estimate_weighted_log_prob\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_weighted_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    475\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[32m    476\u001b[39m \n\u001b[32m    477\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    483\u001b[39m \u001b[33;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m._estimate_log_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_gaussian_mixture.py:839\u001b[39m, in \u001b[36mGaussianMixture._estimate_log_prob\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_log_gaussian_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecisions_cholesky_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcovariance_type\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Thesis/.venv/lib/python3.13/site-packages/sklearn/mixture/_gaussian_mixture.py:486\u001b[39m, in \u001b[36m_estimate_log_gaussian_prob\u001b[39m\u001b[34m(X, means, precisions_chol, covariance_type)\u001b[39m\n\u001b[32m    484\u001b[39m     log_prob = np.empty((n_samples, n_components), dtype=X.dtype)\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, (mu, prec_chol) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(means, precisions_chol)):\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m         y = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec_chol\u001b[49m\u001b[43m)\u001b[49m - np.dot(mu, prec_chol)\n\u001b[32m    487\u001b[39m         log_prob[:, k] = np.sum(np.square(y), axis=\u001b[32m1\u001b[39m)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m covariance_type == \u001b[33m\"\u001b[39m\u001b[33mtied\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "train_path = \"Classification_Combined_Data/S1_S2_train_data_60hz.csv\"\n",
    "test_path  = \"Classification_Combined_Data/S1_S2_test_data_60hz.csv\"\n",
    "\n",
    "# Grid\n",
    "# COMPONENT_GRID = [2, 3, 4, 6, 8, 10]\n",
    "# COVTYPE_GRID   = [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "\n",
    "COMPONENT_GRID = [10]\n",
    "COVTYPE_GRID   = [\"full\"]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "label_map = {\n",
    "    'Not Drowsy': 'alert',\n",
    "    'Slight': 'drowsy',\n",
    "    'Moderate': 'drowsy',\n",
    "    'Very': 'drowsy'\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load\n",
    "# -----------------------------\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "keep = [\"Not Drowsy\", \"Slight\", \"Moderate\", \"Very\"]\n",
    "df_train = df_train[df_train[\"Label\"].isin(keep)].copy()\n",
    "df_test  = df_test[df_test[\"Label\"].isin(keep)].copy()\n",
    "\n",
    "df_train[\"MappedLabel\"] = df_train[\"Label\"].map(label_map)\n",
    "df_test[\"MappedLabel\"]  = df_test[\"Label\"].map(label_map)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Encode labels (EVAL ONLY)\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train[\"MappedLabel\"])\n",
    "y_test  = le.transform(df_test[\"MappedLabel\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Features\n",
    "# -----------------------------\n",
    "exclude_cols = [\"Label\", \"MappedLabel\", \"ID\", \"Study\", \"window_start\"]\n",
    "feature_cols = [c for c in df_train.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = df_train[feature_cols].to_numpy()\n",
    "X_test  = df_test[feature_cols].to_numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Scale (fit on train only)\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Manual grid search (rank by BIC, show BIC/AIC for each)\n",
    "# -----------------------------\n",
    "results = []\n",
    "best = None  # (bic, aic, K, cov_type, fitted_model)\n",
    "\n",
    "for K in COMPONENT_GRID:\n",
    "    for cov_type in COVTYPE_GRID:\n",
    "        try:\n",
    "            gmm = GaussianMixture(\n",
    "                n_components=K,\n",
    "                covariance_type=cov_type,\n",
    "                n_init=20,\n",
    "                init_params=\"kmeans\",\n",
    "                max_iter=1000,\n",
    "                tol=1e-5,\n",
    "                reg_covar=1e-5,\n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "            gmm.fit(X_train_s)\n",
    "\n",
    "            bic = gmm.bic(X_train_s)\n",
    "            aic = gmm.aic(X_train_s)\n",
    "\n",
    "            results.append({\"K\": K, \"cov_type\": cov_type, \"BIC\": bic, \"AIC\": aic})\n",
    "\n",
    "            if best is None or bic < best[0] or (bic == best[0] and aic < best[1]):\n",
    "                best = (bic, aic, K, cov_type, gmm)\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append({\"K\": K, \"cov_type\": cov_type, \"BIC\": np.nan, \"AIC\": np.nan, \"error\": str(e)})\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values([\"BIC\", \"AIC\"], ascending=True)\n",
    "print(\"=== GRID RESULTS (ranked by BIC then AIC) ===\")\n",
    "display(df_results)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Evaluate best model only (unsupervised fit + train-only mapping)\n",
    "# -----------------------------\n",
    "best_bic, best_aic, best_K, best_cov, best_gmm = best\n",
    "print(\"\\n=== BEST MODEL ===\")\n",
    "print(f\"K={best_K}, covariance_type={best_cov}, BIC={best_bic:.2f}, AIC={best_aic:.2f}\")\n",
    "\n",
    "train_clusters = best_gmm.predict(X_train_s)\n",
    "test_clusters  = best_gmm.predict(X_test_s)\n",
    "\n",
    "n_labels = len(le.classes_)\n",
    "counts = np.zeros((best_K, n_labels), dtype=int)\n",
    "for c, y in zip(train_clusters, y_train):\n",
    "    counts[c, y] += 1\n",
    "\n",
    "# Hungarian assignment for one-to-one part\n",
    "cost = counts.max() - counts\n",
    "row_ind, col_ind = linear_sum_assignment(cost)\n",
    "cluster_to_label = {r: c for r, c in zip(row_ind, col_ind)}\n",
    "\n",
    "# If K > n_labels, map leftover clusters to majority label within that cluster\n",
    "unassigned = set(range(best_K)) - set(cluster_to_label.keys())\n",
    "for c in unassigned:\n",
    "    if counts[c].sum() == 0:\n",
    "        cluster_to_label[c] = int(np.bincount(y_train).argmax())\n",
    "    else:\n",
    "        cluster_to_label[c] = int(counts[c].argmax())\n",
    "\n",
    "y_pred_test = np.array([cluster_to_label[c] for c in test_clusters])\n",
    "\n",
    "print(\"\\n--- TEST RESULTS (best model only) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_test, average=\"macro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_pred_test, average=\"weighted\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=le.classes_))\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Optional: write per-cluster posteriors for best model\n",
    "# -----------------------------\n",
    "probs_test = best_gmm.predict_proba(X_test_s)  # (n_test, best_K)\n",
    "\n",
    "df_out = df_test.copy()\n",
    "df_out[\"GMM_cluster\"] = test_clusters\n",
    "df_out[\"GMM_pred_label\"] = le.inverse_transform(y_pred_test)\n",
    "\n",
    "for k in range(best_K):\n",
    "    df_out[f\"GMM_prob_cluster_{k}\"] = probs_test[:, k]\n",
    "\n",
    "df_out.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abee2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GRID RESULTS (ranked by macro F1 on TEST, tie-breaker BIC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>cov_type</th>\n",
       "      <th>BIC</th>\n",
       "      <th>AIC</th>\n",
       "      <th>macro_f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>full</td>\n",
       "      <td>5.658551e+07</td>\n",
       "      <td>5.657418e+07</td>\n",
       "      <td>0.530594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K cov_type           BIC           AIC  macro_f1_test\n",
       "0  2     full  5.658551e+07  5.657418e+07       0.530594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BEST SUPERVISED GMM CLASSIFIER ===\n",
      "K=2, covariance_type=full, test macro F1=0.5306, BIC=56585508.48, AIC=56574175.74\n",
      "\n",
      "--- TEST RESULTS (best model only) ---\n",
      "Accuracy: 0.6625126055862407\n",
      "Macro F1: 0.5305940635752153\n",
      "Weighted F1: 0.6489584529210202\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 21464  63548]\n",
      " [ 45886 193363]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.32      0.25      0.28     85012\n",
      "      drowsy       0.75      0.81      0.78    239249\n",
      "\n",
      "    accuracy                           0.66    324261\n",
      "   macro avg       0.54      0.53      0.53    324261\n",
      "weighted avg       0.64      0.66      0.65    324261\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>UNIX</th>\n",
       "      <th>EAR_mean</th>\n",
       "      <th>MAR_inner</th>\n",
       "      <th>MAR_outer</th>\n",
       "      <th>AU01_r</th>\n",
       "      <th>AU15_r</th>\n",
       "      <th>AU25_r</th>\n",
       "      <th>AU26_r</th>\n",
       "      <th>...</th>\n",
       "      <th>gaze_angle_y</th>\n",
       "      <th>swAngle</th>\n",
       "      <th>laneDevPosition</th>\n",
       "      <th>laneDev_OffsetfrmLaneCentre</th>\n",
       "      <th>speed</th>\n",
       "      <th>Study</th>\n",
       "      <th>MappedLabel</th>\n",
       "      <th>GMM_pred_label</th>\n",
       "      <th>GMM_prob_alert</th>\n",
       "      <th>GMM_prob_drowsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.007927</td>\n",
       "      <td>0.296455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>4.725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.412129</td>\n",
       "      <td>60.865053</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.999944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.276723</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.298315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397667</td>\n",
       "      <td>4.725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.420328</td>\n",
       "      <td>60.710593</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.274216</td>\n",
       "      <td>0.008958</td>\n",
       "      <td>0.294492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>4.725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.403500</td>\n",
       "      <td>60.580803</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.273122</td>\n",
       "      <td>0.008595</td>\n",
       "      <td>0.299090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402667</td>\n",
       "      <td>4.650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.363394</td>\n",
       "      <td>60.451293</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.999942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.270864</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.298286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397333</td>\n",
       "      <td>4.050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.297956</td>\n",
       "      <td>60.314040</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.272033</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.294080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>3.225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.214741</td>\n",
       "      <td>60.185303</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.999932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.271703</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>0.292723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>3.150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.213028</td>\n",
       "      <td>60.040973</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.999877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>0.296644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406333</td>\n",
       "      <td>3.150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.228132</td>\n",
       "      <td>59.913003</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>0.010466</td>\n",
       "      <td>0.304193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.225552</td>\n",
       "      <td>59.769407</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.273754</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.304829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407667</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.208202</td>\n",
       "      <td>59.642097</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.272915</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.300935</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414667</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.177140</td>\n",
       "      <td>59.515083</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.999846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.269752</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>0.294280</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.129751</td>\n",
       "      <td>59.380447</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.999883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.073086</td>\n",
       "      <td>59.253980</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.999912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.281267</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>0.296536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411667</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.994824</td>\n",
       "      <td>59.112030</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.999843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.280332</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.936204</td>\n",
       "      <td>58.986130</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.999871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.274199</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.296670</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412333</td>\n",
       "      <td>2.700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.977370</td>\n",
       "      <td>58.844793</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.999738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.270390</td>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.293351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418333</td>\n",
       "      <td>2.775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.001699</td>\n",
       "      <td>58.735070</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.999793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.279291</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.293582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.019868</td>\n",
       "      <td>58.594243</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.999906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.276064</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.301648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>3.450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.022608</td>\n",
       "      <td>58.484887</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.999933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Drowsy</td>\n",
       "      <td>1.638561e+09</td>\n",
       "      <td>0.270827</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.309723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>4.050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.010130</td>\n",
       "      <td>58.336633</td>\n",
       "      <td>S1</td>\n",
       "      <td>alert</td>\n",
       "      <td>drowsy</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       Label          UNIX  EAR_mean  MAR_inner  MAR_outer    AU01_r  \\\n",
       "0   10.0  Not Drowsy  1.638561e+09  0.271028   0.007927   0.296455  0.000000   \n",
       "1   10.0  Not Drowsy  1.638561e+09  0.276723   0.009840   0.298315  0.000000   \n",
       "2   10.0  Not Drowsy  1.638561e+09  0.274216   0.008958   0.294492  0.000000   \n",
       "3   10.0  Not Drowsy  1.638561e+09  0.273122   0.008595   0.299090  0.000000   \n",
       "4   10.0  Not Drowsy  1.638561e+09  0.270864   0.008658   0.298286  0.000000   \n",
       "5   10.0  Not Drowsy  1.638561e+09  0.272033   0.008661   0.294080  0.000000   \n",
       "6   10.0  Not Drowsy  1.638561e+09  0.271703   0.005547   0.292723  0.000000   \n",
       "7   10.0  Not Drowsy  1.638561e+09  0.269833   0.009218   0.296644  0.000000   \n",
       "8   10.0  Not Drowsy  1.638561e+09  0.272838   0.010466   0.304193  0.000000   \n",
       "9   10.0  Not Drowsy  1.638561e+09  0.273754   0.011152   0.304829  0.000000   \n",
       "10  10.0  Not Drowsy  1.638561e+09  0.272915   0.010176   0.300935  0.070000   \n",
       "11  10.0  Not Drowsy  1.638561e+09  0.269752   0.008434   0.294280  0.010000   \n",
       "12  10.0  Not Drowsy  1.638561e+09  0.271900   0.010394   0.296600  0.000000   \n",
       "13  10.0  Not Drowsy  1.638561e+09  0.281267   0.012307   0.296536  0.000000   \n",
       "14  10.0  Not Drowsy  1.638561e+09  0.280332   0.011697   0.296518  0.003333   \n",
       "15  10.0  Not Drowsy  1.638561e+09  0.274199   0.012913   0.296670  0.006667   \n",
       "16  10.0  Not Drowsy  1.638561e+09  0.270390   0.009790   0.293351  0.000000   \n",
       "17  10.0  Not Drowsy  1.638561e+09  0.279291   0.007168   0.293582  0.000000   \n",
       "18  10.0  Not Drowsy  1.638561e+09  0.276064   0.014110   0.301648  0.000000   \n",
       "19  10.0  Not Drowsy  1.638561e+09  0.270827   0.028168   0.309723  0.000000   \n",
       "\n",
       "      AU15_r    AU25_r    AU26_r  ...  gaze_angle_y  swAngle  laneDevPosition  \\\n",
       "0   0.006667  0.120000  0.146667  ...      0.390000    4.725              1.0   \n",
       "1   0.050000  0.146667  0.066667  ...      0.397667    4.725              1.0   \n",
       "2   0.186667  0.380000  0.200000  ...      0.387000    4.725              1.0   \n",
       "3   0.086667  0.450000  0.203333  ...      0.402667    4.650              1.0   \n",
       "4   0.046667  0.296667  0.573333  ...      0.397333    4.050              1.0   \n",
       "5   0.000000  0.266667  0.316667  ...      0.395000    3.225              1.0   \n",
       "6   0.023333  0.250000  0.006667  ...      0.398000    3.150              1.0   \n",
       "7   0.273333  0.090000  0.143333  ...      0.406333    3.150              1.0   \n",
       "8   0.360000  0.040000  0.230000  ...      0.401000    3.000              1.0   \n",
       "9   0.140000  0.000000  0.073333  ...      0.407667    2.700              1.0   \n",
       "10  0.013333  0.000000  0.000000  ...      0.414667    2.700              1.0   \n",
       "11  0.100000  0.000000  0.000000  ...      0.406000    2.700              1.0   \n",
       "12  0.196667  0.043333  0.086667  ...      0.406667    2.700              1.0   \n",
       "13  0.036667  0.166667  0.023333  ...      0.411667    2.700              1.0   \n",
       "14  0.116667  0.153333  0.146667  ...      0.403333    2.700              1.0   \n",
       "15  0.020000  0.160000  0.060000  ...      0.412333    2.700              1.0   \n",
       "16  0.040000  0.170000  0.056667  ...      0.418333    2.775              1.0   \n",
       "17  0.203333  0.086667  0.223333  ...      0.405000    3.000              1.0   \n",
       "18  0.046667  0.253333  0.196667  ...      0.413000    3.450              1.0   \n",
       "19  0.046667  0.263333  0.333333  ...      0.420000    4.050              1.0   \n",
       "\n",
       "    laneDev_OffsetfrmLaneCentre      speed  Study  MappedLabel  \\\n",
       "0                     -1.412129  60.865053     S1        alert   \n",
       "1                     -1.420328  60.710593     S1        alert   \n",
       "2                     -1.403500  60.580803     S1        alert   \n",
       "3                     -1.363394  60.451293     S1        alert   \n",
       "4                     -1.297956  60.314040     S1        alert   \n",
       "5                     -1.214741  60.185303     S1        alert   \n",
       "6                     -1.213028  60.040973     S1        alert   \n",
       "7                     -1.228132  59.913003     S1        alert   \n",
       "8                     -1.225552  59.769407     S1        alert   \n",
       "9                     -1.208202  59.642097     S1        alert   \n",
       "10                    -1.177140  59.515083     S1        alert   \n",
       "11                    -1.129751  59.380447     S1        alert   \n",
       "12                    -1.073086  59.253980     S1        alert   \n",
       "13                    -0.994824  59.112030     S1        alert   \n",
       "14                    -0.936204  58.986130     S1        alert   \n",
       "15                    -0.977370  58.844793     S1        alert   \n",
       "16                    -1.001699  58.735070     S1        alert   \n",
       "17                    -1.019868  58.594243     S1        alert   \n",
       "18                    -1.022608  58.484887     S1        alert   \n",
       "19                    -1.010130  58.336633     S1        alert   \n",
       "\n",
       "    GMM_pred_label  GMM_prob_alert  GMM_prob_drowsy  \n",
       "0           drowsy        0.000056         0.999944  \n",
       "1           drowsy        0.000064         0.999936  \n",
       "2           drowsy        0.000040         0.999960  \n",
       "3           drowsy        0.000058         0.999942  \n",
       "4           drowsy        0.000052         0.999948  \n",
       "5           drowsy        0.000068         0.999932  \n",
       "6           drowsy        0.000123         0.999877  \n",
       "7           drowsy        0.000060         0.999940  \n",
       "8           drowsy        0.000027         0.999973  \n",
       "9           drowsy        0.000054         0.999946  \n",
       "10          drowsy        0.000154         0.999846  \n",
       "11          drowsy        0.000117         0.999883  \n",
       "12          drowsy        0.000088         0.999912  \n",
       "13          drowsy        0.000157         0.999843  \n",
       "14          drowsy        0.000129         0.999871  \n",
       "15          drowsy        0.000262         0.999738  \n",
       "16          drowsy        0.000207         0.999793  \n",
       "17          drowsy        0.000094         0.999906  \n",
       "18          drowsy        0.000067         0.999933  \n",
       "19          drowsy        0.000040         0.999960  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "train_path = \"Classification_Combined_Data/S1_S2_train_data_60hz.csv\"\n",
    "test_path  = \"Classification_Combined_Data/S1_S2_test_data_60hz.csv\"\n",
    "\n",
    "# COMPONENT_GRID = [2, 3, 4, 6, 8, 10]\n",
    "# COVTYPE_GRID   = [\"full\", \"tied\", \"diag\", \"spherical\"]\n",
    "\n",
    "COMPONENT_GRID = [2]\n",
    "COVTYPE_GRID   = [\"full\"]\n",
    "\n",
    "RANDOM_STATE   = 42\n",
    "\n",
    "label_map = {\n",
    "    'Not Drowsy': 'alert',\n",
    "    'Slight': 'drowsy',\n",
    "    'Moderate': 'drowsy',\n",
    "    'Very': 'drowsy'\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load\n",
    "# -----------------------------\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "keep = [\"Not Drowsy\", \"Slight\", \"Moderate\", \"Very\"]\n",
    "df_train = df_train[df_train[\"Label\"].isin(keep)].copy()\n",
    "df_test  = df_test[df_test[\"Label\"].isin(keep)].copy()\n",
    "\n",
    "df_train[\"MappedLabel\"] = df_train[\"Label\"].map(label_map)\n",
    "df_test[\"MappedLabel\"]  = df_test[\"Label\"].map(label_map)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Encode labels\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train[\"MappedLabel\"])\n",
    "y_test  = le.transform(df_test[\"MappedLabel\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Features\n",
    "# -----------------------------\n",
    "exclude_cols = [\"Label\", \"MappedLabel\", \"ID\", \"Study\", \"window_start\"]\n",
    "feature_cols = [c for c in df_train.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = df_train[feature_cols].to_numpy()\n",
    "X_test  = df_test[feature_cols].to_numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Scale (fit on train only)\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) SUPERVISED \"GMM\": one GMM per class (generative classifier)\n",
    "#    Score(x|class) + prior(class) -> choose best class\n",
    "#    We'll tune: covariance_type (shared), n_components per class (same K for simplicity)\n",
    "# -----------------------------\n",
    "def fit_class_gmms(X, y, K, cov_type):\n",
    "    class_models = {}\n",
    "    class_priors = {}\n",
    "    for cls in np.unique(y):\n",
    "        Xc = X[y == cls]\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=K,\n",
    "            covariance_type=cov_type,\n",
    "            n_init=20,\n",
    "            init_params=\"kmeans\",\n",
    "            max_iter=1000,\n",
    "            tol=1e-5,\n",
    "            reg_covar=1e-5,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        gmm.fit(Xc)\n",
    "        class_models[cls] = gmm\n",
    "        class_priors[cls] = len(Xc) / len(X)\n",
    "    return class_models, class_priors\n",
    "\n",
    "def predict_class_gmms(X, class_models, class_priors):\n",
    "    classes = sorted(class_models.keys())\n",
    "    # log p(x|y=c) + log p(y=c)\n",
    "    scores = np.column_stack([\n",
    "        class_models[c].score_samples(X) + np.log(class_priors[c])\n",
    "        for c in classes\n",
    "    ])\n",
    "    pred = np.array([classes[i] for i in np.argmax(scores, axis=1)])\n",
    "    return pred, scores\n",
    "\n",
    "results = []\n",
    "best = None  # (metric, K, cov_type, models, priors)\n",
    "\n",
    "for K in COMPONENT_GRID:\n",
    "    for cov_type in COVTYPE_GRID:\n",
    "        try:\n",
    "            models, priors = fit_class_gmms(X_train_s, y_train, K, cov_type)\n",
    "\n",
    "            # Use TRAIN AIC/BIC summed across class-models as a comparable score\n",
    "            bic = sum(models[c].bic(X_train_s[y_train == c]) for c in models)\n",
    "            aic = sum(models[c].aic(X_train_s[y_train == c]) for c in models)\n",
    "\n",
    "            # Evaluate on test (since now supervised)\n",
    "            y_pred_test, _ = predict_class_gmms(X_test_s, models, priors)\n",
    "            macro_f1 = f1_score(y_test, y_pred_test, average=\"macro\")\n",
    "\n",
    "            results.append({\"K\": K, \"cov_type\": cov_type, \"BIC\": bic, \"AIC\": aic, \"macro_f1_test\": macro_f1})\n",
    "\n",
    "            # Pick best by macro F1 (tie-breaker: lower BIC)\n",
    "            if best is None or macro_f1 > best[0] or (macro_f1 == best[0] and bic < best[1]):\n",
    "                best = (macro_f1, bic, aic, K, cov_type, models, priors)\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append({\"K\": K, \"cov_type\": cov_type, \"BIC\": np.nan, \"AIC\": np.nan, \"macro_f1_test\": np.nan, \"error\": str(e)})\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values([\"macro_f1_test\", \"BIC\"], ascending=[False, True])\n",
    "print(\"=== GRID RESULTS (ranked by macro F1 on TEST, tie-breaker BIC) ===\")\n",
    "display(df_results)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Report best model only\n",
    "# -----------------------------\n",
    "best_f1, best_bic, best_aic, best_K, best_cov, best_models, best_priors = best\n",
    "print(\"\\n=== BEST SUPERVISED GMM CLASSIFIER ===\")\n",
    "print(f\"K={best_K}, covariance_type={best_cov}, test macro F1={best_f1:.4f}, BIC={best_bic:.2f}, AIC={best_aic:.2f}\")\n",
    "\n",
    "y_pred_test, scores_test = predict_class_gmms(X_test_s, best_models, best_priors)\n",
    "\n",
    "print(\"\\n--- TEST RESULTS (best model only) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred_test, average=\"macro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_pred_test, average=\"weighted\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=le.classes_))\n",
    "\n",
    "# Optional: class posteriors (softmax over log-scores)\n",
    "probs_test = np.exp(scores_test - scores_test.max(axis=1, keepdims=True))\n",
    "probs_test = probs_test / probs_test.sum(axis=1, keepdims=True)\n",
    "\n",
    "df_out = df_test.copy()\n",
    "df_out[\"GMM_pred_label\"] = le.inverse_transform(y_pred_test)\n",
    "for idx, cls in enumerate(sorted(best_models.keys())):\n",
    "    df_out[f\"GMM_prob_{le.inverse_transform([cls])[0]}\"] = probs_test[:, idx]\n",
    "\n",
    "df_out.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
