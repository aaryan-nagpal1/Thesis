{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9345d1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7380835380835381\n",
      "Macro F1: 0.49224288902235735\n",
      "Weighted F1: 0.6597825968924417\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  43  492]\n",
      " [  41 1459]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.51      0.08      0.14       535\n",
      "      drowsy       0.75      0.97      0.85      1500\n",
      "\n",
      "    accuracy                           0.74      2035\n",
      "   macro avg       0.63      0.53      0.49      2035\n",
      "weighted avg       0.69      0.74      0.66      2035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "train_path = \"Classification_Combined_Data/S1_S2_train_data.csv\"\n",
    "test_path  = \"Classification_Combined_Data/S1_S2_test_data.csv\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "label_map = {\n",
    "    'Not Drowsy': 'alert',\n",
    "    'Slight': 'drowsy',\n",
    "    'Moderate': 'drowsy',\n",
    "    'Very': 'drowsy'\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load\n",
    "# -----------------------------\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "keep = [\"Not Drowsy\", \"Slight\", \"Moderate\", \"Very\"]\n",
    "df_train = df_train[df_train[\"Label\"].isin(keep)].copy()\n",
    "df_test  = df_test[df_test[\"Label\"].isin(keep)].copy()\n",
    "\n",
    "df_train[\"MappedLabel\"] = df_train[\"Label\"].map(label_map)\n",
    "df_test[\"MappedLabel\"]  = df_test[\"Label\"].map(label_map)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Encode labels\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train[\"MappedLabel\"])\n",
    "y_test  = le.transform(df_test[\"MappedLabel\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Features (no scaling needed for TabPFN)\n",
    "# -----------------------------\n",
    "exclude_cols = [\"Label\", \"MappedLabel\", \"ID\", \"Study\", \"window_start\"]\n",
    "feature_cols = [c for c in df_train.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = df_train[feature_cols].to_numpy()\n",
    "X_test  = df_test[feature_cols].to_numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fit TabPFN on GPU\n",
    "# -----------------------------\n",
    "clf = TabPFNClassifier(\n",
    "    device=\"cuda\",              # <-- forces GPU\n",
    "    random_state=RANDOM_STATE,\n",
    "    # If you hit VRAM issues, try lower precision:\n",
    "    # inference_precision=\"fp16\",\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Evaluate on TEST\n",
    "# -----------------------------\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)  # shape (n, n_classes)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5077136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "cuda: True\n",
      "gpu: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"cuda:\", torch.cuda.is_available())\n",
    "print(\"gpu:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "921ab773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: You are downloading 'tabicl-classifier-v2-20260212.ckpt', the latest best-performing version, used in our TabICLv2 paper.\n",
      "\n",
      "Checkpoint 'tabicl-classifier-v2-20260212.ckpt' not cached.\n",
      " Downloading from Hugging Face Hub (jingang/TabICL).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarya\\Desktop\\Thesis\\Thesis\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aarya\\.cache\\huggingface\\hub\\models--jingang--TabICL. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7454545454545455\n",
      "Macro F1: 0.5234286840658546\n",
      "Weighted F1: 0.6776799124604455\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  64  471]\n",
      " [  47 1453]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.58      0.12      0.20       535\n",
      "      drowsy       0.76      0.97      0.85      1500\n",
      "\n",
      "    accuracy                           0.75      2035\n",
      "   macro avg       0.67      0.54      0.52      2035\n",
      "weighted avg       0.71      0.75      0.68      2035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from tabicl import TabICLClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "train_path = \"Classification_Combined_Data/S1_S2_train_data.csv\"\n",
    "test_path  = \"Classification_Combined_Data/S1_S2_test_data.csv\"\n",
    "\n",
    "label_map = {\n",
    "    \"Not Drowsy\": \"alert\",\n",
    "    \"Slight\": \"drowsy\",\n",
    "    \"Moderate\": \"drowsy\",\n",
    "    \"Very\": \"drowsy\",\n",
    "}\n",
    "keep = [\"Not Drowsy\", \"Slight\", \"Moderate\", \"Very\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load + map labels\n",
    "# -----------------------------\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "df_train = df_train[df_train[\"Label\"].isin(keep)].copy()\n",
    "df_test  = df_test[df_test[\"Label\"].isin(keep)].copy()\n",
    "\n",
    "df_train[\"MappedLabel\"] = df_train[\"Label\"].map(label_map)\n",
    "df_test[\"MappedLabel\"]  = df_test[\"Label\"].map(label_map)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Encode labels (for metrics)\n",
    "# -----------------------------\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train[\"MappedLabel\"])\n",
    "y_test  = le.transform(df_test[\"MappedLabel\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Features\n",
    "# -----------------------------\n",
    "exclude_cols = [c for c in [\"Label\", \"MappedLabel\", \"ID\", \"Study\", \"window_start\"] if c in df_train.columns]\n",
    "feature_cols = [c for c in df_train.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = df_train[feature_cols].to_numpy(dtype=np.float32)\n",
    "X_test  = df_test[feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fit TabICL on GPU\n",
    "# -----------------------------\n",
    "clf = TabICLClassifier(\n",
    "    device=\"cuda\",        # forces GPU (or use None for auto)\n",
    "    use_amp=\"auto\",       # mixed precision if supported\n",
    "    n_estimators=8,       # default is 8; more = slower, often slightly better\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Optional speedup if you will call predict multiple times with same train set:\n",
    "# clf.fit(X_train, y_train, kv_cache=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Predict + evaluate\n",
    "# -----------------------------\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc1c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"external/realmlp\")\n",
    "\n",
    "from mlp import Standalone_RealMLP_TD_S_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf682c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7267813267813268\n",
      "Macro F1: 0.5126008863525147\n",
      "Weighted F1: 0.6658137292093002\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  65  470]\n",
      " [  86 1414]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       alert       0.43      0.12      0.19       535\n",
      "      drowsy       0.75      0.94      0.84      1500\n",
      "\n",
      "    accuracy                           0.73      2035\n",
      "   macro avg       0.59      0.53      0.51      2035\n",
      "weighted avg       0.67      0.73      0.67      2035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarya\\Desktop\\Thesis\\Thesis\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from mlp import Standalone_RealMLP_TD_S_Classifier\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility (optional)\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# -----------------------------\n",
    "# Load + preprocess\n",
    "# -----------------------------\n",
    "train_path = \"Classification_Combined_Data/S1_S2_train_data.csv\"\n",
    "test_path  = \"Classification_Combined_Data/S1_S2_test_data.csv\"\n",
    "\n",
    "label_map = {\n",
    "    \"Not Drowsy\": \"alert\",\n",
    "    \"Slight\": \"drowsy\",\n",
    "    \"Moderate\": \"drowsy\",\n",
    "    \"Very\": \"drowsy\",\n",
    "}\n",
    "keep = [\"Not Drowsy\", \"Slight\", \"Moderate\", \"Very\"]\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test  = pd.read_csv(test_path)\n",
    "\n",
    "df_train = df_train[df_train[\"Label\"].isin(keep)].copy()\n",
    "df_test  = df_test[df_test[\"Label\"].isin(keep)].copy()\n",
    "\n",
    "df_train[\"MappedLabel\"] = df_train[\"Label\"].map(label_map)\n",
    "df_test[\"MappedLabel\"]  = df_test[\"Label\"].map(label_map)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train[\"MappedLabel\"])\n",
    "y_test  = le.transform(df_test[\"MappedLabel\"])\n",
    "\n",
    "exclude_cols = [\"Label\", \"MappedLabel\", \"ID\", \"Study\", \"window_start\"]\n",
    "feature_cols = [c for c in df_train.columns if c not in exclude_cols]\n",
    "\n",
    "X_train = df_train[feature_cols].to_numpy(dtype=np.float32)\n",
    "X_test  = df_test[feature_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# Train RealMLP (GPU)\n",
    "# -----------------------------\n",
    "clf = Standalone_RealMLP_TD_S_Classifier(device=\"cuda\")  # <- no random_state arg\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate\n",
    "# -----------------------------\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"Weighted F1:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
